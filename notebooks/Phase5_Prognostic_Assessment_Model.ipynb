{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6549d7b9",
   "metadata": {},
   "source": [
    "# Phase 5: Prognostic Outcome Assessment Model\n",
    "\n",
    "This notebook builds an ensemble prognostic model that combines predictions and features from prior phases to estimate neurodevelopmental outcome risk (continuous 0â€“1 and categorical prognosis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891cede8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2745d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ace96b",
   "metadata": {},
   "source": [
    "## 2. Load Predictions and Features from Previous Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2693b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base data: (43200, 51)\n",
      "   neuro_outcome_72h prognosis_bucket\n",
      "0                  0        Excellent\n",
      "1                  0        Excellent\n",
      "2                  0        Excellent\n",
      "3                  0        Excellent\n",
      "4                  0        Excellent\n",
      "Feature matrix: (43200, 3)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_PATH = os.path.join('..', 'data', 'preprocessed_normalized_dataset.csv')\n",
    "PHASE4_FEATURES_PATH = os.path.join('..', 'models', 'phase4_prediction_features.json')\n",
    "SEIZURE_METRICS_PATH = os.path.join('..', 'models', 'seizure_model_metrics.json')\n",
    "SEPSIS_METRICS_PATH = os.path.join('..', 'models', 'sepsis_model_metrics.json')\n",
    "CARDIAC_METRICS_PATH = os.path.join('..', 'models', 'cardiac_model_metrics.json')\n",
    "RENAL_METRICS_PATH = os.path.join('..', 'models', 'renal_model_metrics.json')\n",
    "\n",
    "# Load base data\n",
    "base_df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded base data:\", base_df.shape)\n",
    "\n",
    "# Create/confirm the Phase2 outcome label if present (e.g., neuro_outcome_72h)\n",
    "if 'neuro_outcome_72h' not in base_df.columns:\n",
    "    # Heuristic outcome: combine severity, temp stability, metabolic recovery\n",
    "    # Normalize inputs as proxy\n",
    "    sev = base_df.get('hie_severity', pd.Series(1, index=base_df.index)).fillna(1)\n",
    "    temp_stab = (base_df.get('temp_grad_1h', pd.Series(0, index=base_df.index)).abs() < 0.2).astype(int)\n",
    "    metabolic_ok = ((base_df['lactate'] < 4.0) & (base_df['ph'] >= 7.30)).astype(int)\n",
    "    # Map to categorical risk: 0 best .. 4 worst, then normalize to 0..1\n",
    "    score = (4 - (temp_stab + metabolic_ok)) + sev\n",
    "    score_norm = (score - score.min()) / (score.max() - score.min() + 1e-9)\n",
    "    base_df['neuro_outcome_72h'] = score_norm\n",
    "\n",
    "# Convert to categorical prognosis buckets\n",
    "# Excellent/Good/Moderate/Guarded/Poor\n",
    "bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.01]\n",
    "labels = ['Excellent', 'Good', 'Moderate', 'Guarded', 'Poor']\n",
    "base_df['prognosis_bucket'] = pd.cut(base_df['neuro_outcome_72h'], bins=bins, labels=labels, include_lowest=True)\n",
    "base_df['prognosis_target'] = (base_df['neuro_outcome_72h'] > 0.6).astype(int)  # binary: Guarded/Poor vs others\n",
    "\n",
    "print(base_df[['neuro_outcome_72h', 'prognosis_bucket']].head())\n",
    "\n",
    "# Build feature space: concatenate Phase4 predictions (placeholder: use risk labels) + Phase3 temp features\n",
    "feature_cols = [\n",
    "    # Physiological features\n",
    "    'rectal_temp','heart_rate','systolic_bp','diastolic_bp','spo2','ph','lactate',\n",
    "    'temp_grad_5m','temp_grad_30m','temp_grad_1h','hr_roll_mean','hr_roll_std','map_mmHg','pulse_pressure',\n",
    "    # Phase4 label proxies (in production, replace with model outputs)\n",
    "    'seizure_risk_high','sepsis_risk_flag','cardiac_distress_flag','renal_dysfunction_risk'\n",
    "]\n",
    "feature_cols = [c for c in feature_cols if c in base_df.columns]\n",
    "\n",
    "work_df = base_df.dropna(subset=feature_cols + ['prognosis_target']).copy()\n",
    "X = work_df[feature_cols].to_numpy(dtype=float)\n",
    "y_bin = work_df['prognosis_target'].to_numpy(dtype=int)\n",
    "print(\"Feature matrix:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4245f70",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering for Prognosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aabe48ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['cardiac_distress_flag', 'heart_rate', 'lactate', 'map_mmHg', 'ph', 'rectal_temp', 'sepsis_risk_flag', 'temp_grad_1h'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Aggregate per patient to summarize course features\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mpatient_id\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m work_df.columns:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     agg_df = \u001b[43mwork_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpatient_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrectal_temp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemp_grad_1h\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mheart_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmap_mmHg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpulse_pressure\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlactate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mph\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseizure_risk_high\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msepsis_risk_flag\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcardiac_distress_flag\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrenal_dysfunction_risk\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprognosis_target\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Flatten MultiIndex columns\u001b[39;00m\n\u001b[32m     18\u001b[39m     agg_df.columns = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a,b \u001b[38;5;129;01min\u001b[39;00m agg_df.columns]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anand\\OneDrive\\Desktop\\Personalized_Adaptive_Hypothermia\\.venv\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anand\\OneDrive\\Desktop\\Personalized_Adaptive_Hypothermia\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anand\\OneDrive\\Desktop\\Personalized_Adaptive_Hypothermia\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anand\\OneDrive\\Desktop\\Personalized_Adaptive_Hypothermia\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1603\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1598\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1601\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1602\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anand\\OneDrive\\Desktop\\Personalized_Adaptive_Hypothermia\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:462\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m is_groupby = \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[32m    461\u001b[39m func = cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m.func)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m func = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m is_non_unique_col = (\n\u001b[32m    465\u001b[39m     selected_obj.ndim == \u001b[32m2\u001b[39m\n\u001b[32m    466\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj.columns.nunique() < \u001b[38;5;28mlen\u001b[39m(selected_obj.columns)\n\u001b[32m    467\u001b[39m )\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anand\\OneDrive\\Desktop\\Personalized_Adaptive_Hypothermia\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:663\u001b[39m, in \u001b[36mApply.normalize_dictlike_arg\u001b[39m\u001b[34m(self, how, obj, func)\u001b[39m\n\u001b[32m    661\u001b[39m     cols = Index(\u001b[38;5;28mlist\u001b[39m(func.keys())).difference(obj.columns, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    665\u001b[39m aggregator_types = (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: \"Column(s) ['cardiac_distress_flag', 'heart_rate', 'lactate', 'map_mmHg', 'ph', 'rectal_temp', 'sepsis_risk_flag', 'temp_grad_1h'] do not exist\""
     ]
    }
   ],
   "source": [
    "# Aggregate per patient to summarize course features\n",
    "if 'patient_id' in work_df.columns:\n",
    "    # Use actual column names from preprocessed data\n",
    "    available_agg_cols = {\n",
    "        'rectal_temperature_c': ['mean','std'],\n",
    "        'heart_rate_bpm': ['mean','std'],\n",
    "        'systolic_bp_mmhg': ['mean','min'],\n",
    "        'diastolic_bp_mmhg': ['mean','min'],\n",
    "        'lactate_mmol': ['mean','max'],\n",
    "        'pH': ['mean','min'],\n",
    "        'neuro_outcome_72h': ['max']\n",
    "    }\n",
    "    # Filter to only existing columns\n",
    "    agg_cols = {k: v for k, v in available_agg_cols.items() if k in work_df.columns}\n",
    "    \n",
    "    agg_df = work_df.groupby('patient_id').agg(agg_cols)\n",
    "    # Flatten MultiIndex columns\n",
    "    agg_df.columns = [f\"{a}_{b}\" for a,b in agg_df.columns]\n",
    "    agg_df = agg_df.reset_index()\n",
    "    # Targets\n",
    "    y_patient = agg_df['neuro_outcome_72h_max'].to_numpy(dtype=int)\n",
    "    # Features\n",
    "    feature_cols_patient = [c for c in agg_df.columns if c not in ['patient_id','neuro_outcome_72h_max']]\n",
    "    X_patient = agg_df[feature_cols_patient].to_numpy(dtype=float)\n",
    "else:\n",
    "    # Fallback to sample-level\n",
    "    X_patient = X\n",
    "    y_patient = y_bin\n",
    "    feature_cols_patient = feature_cols\n",
    "\n",
    "print(\"Patient-level feature matrix:\", X_patient.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a19de",
   "metadata": {},
   "source": [
    "## 4. Build Prognostic Models (Binary + Multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a304d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_patient, y_patient, test_size=0.2, random_state=42, stratify=y_patient)\n",
    "\n",
    "# Binary prognosis (Guarded/Poor vs others)\n",
    "binary_models = {\n",
    "    'logreg': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "    ]),\n",
    "    'rf': RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'),\n",
    "    'gb': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "binary_metrics = {}\n",
    "for name, clf in binary_models.items():\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    preds = clf.predict(X_te)\n",
    "    proba = clf.predict_proba(X_te)[:, 1] if hasattr(clf, 'predict_proba') else None\n",
    "    auc = roc_auc_score(y_te, proba) if proba is not None else np.nan\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_te, preds, average='binary')\n",
    "    binary_metrics[name] = {'auc': float(auc), 'precision': float(precision), 'recall': float(recall), 'f1': float(f1)}\n",
    "\n",
    "pd.DataFrame(binary_metrics).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b87b1c",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation and Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7afa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best binary model by AUC\n",
    "best_bin_name = max(binary_metrics.items(), key=lambda kv: kv[1]['auc'])[0]\n",
    "best_bin_model = binary_models[best_bin_name]\n",
    "print(\"Best binary prognosis model:\", best_bin_name, binary_metrics[best_bin_name])\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "if hasattr(best_bin_model, 'predict_proba'):\n",
    "    RocCurveDisplay.from_estimator(best_bin_model, X_te, y_te)\n",
    "    plt.title(f\"Binary Prognosis ROC - {best_bin_name}\")\n",
    "    plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_te, best_bin_model.predict(X_te))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Binary Prognosis - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57a4ff",
   "metadata": {},
   "source": [
    "## 6. Prognosis Category Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9880fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map probability to prognosis categories\n",
    "\n",
    "def prognosis_text(prob):\n",
    "    if prob < 0.2:\n",
    "        return \"Excellent\"\n",
    "    elif prob < 0.4:\n",
    "        return \"Good\"\n",
    "    elif prob < 0.6:\n",
    "        return \"Moderate\"\n",
    "    elif prob < 0.8:\n",
    "        return \"Guarded\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "\n",
    "# Example inference for a few samples\n",
    "if hasattr(best_bin_model, 'predict_proba'):\n",
    "    example_probs = best_bin_model.predict_proba(X_te[:10])[:, 1]\n",
    "    mapped = [prognosis_text(p) for p in example_probs]\n",
    "    print(list(zip(example_probs.round(3), mapped)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537a7a8",
   "metadata": {},
   "source": [
    "## 7. Save Prognostic Model & Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ae3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "os.makedirs(os.path.join('..', 'models'), exist_ok=True)\n",
    "\n",
    "# Save best binary prognosis model\n",
    "with open(os.path.join('..', 'models', f'prognosis_model_{best_bin_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(best_bin_model, f)\n",
    "\n",
    "with open(os.path.join('..', 'models', 'prognosis_model_metrics.json'), 'w') as f:\n",
    "    json.dump(binary_metrics, f, indent=2)\n",
    "\n",
    "with open(os.path.join('..', 'models', 'prognosis_feature_columns.json'), 'w') as f:\n",
    "    json.dump(feature_cols_patient, f, indent=2)\n",
    "\n",
    "print(\"Prognosis model and metadata saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
