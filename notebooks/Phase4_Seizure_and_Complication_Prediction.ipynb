{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbaf3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset at ..\\data\\preprocessed_normalized_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Fallback: generate synthetic dataset if expected CSV is missing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = os.path.join('..','data','preprocessed_normalized_dataset.csv')\n",
    "os.makedirs(os.path.join('..','data'), exist_ok=True)\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    np.random.seed(42)\n",
    "    n = 1000\n",
    "    ts = pd.date_range('2025-01-01', periods=n, freq='T')\n",
    "    df = pd.DataFrame({\n",
    "        'patient_id': ['DEMO-001']*n,\n",
    "        'timestamp': ts,\n",
    "        'rectal_temp': np.random.normal(36.5, 0.6, n),\n",
    "        'heart_rate': np.random.normal(120, 20, n).clip(50, 220),\n",
    "        'systolic_bp': np.random.normal(100, 15, n).clip(60, 180),\n",
    "        'diastolic_bp': np.random.normal(65, 10, n).clip(40, 110),\n",
    "        'spo2': np.random.normal(95, 2, n).clip(80, 100),\n",
    "        'ph': np.random.normal(7.38, 0.05, n).clip(7.1, 7.5),\n",
    "        'lactate': np.abs(np.random.normal(2.0, 1.0, n))\n",
    "    })\n",
    "    # Simple engineered features\n",
    "    df['temp_grad_5m'] = df['rectal_temp'].diff().fillna(0)\n",
    "    df['temp_grad_30m'] = df['rectal_temp'].diff(30).fillna(0)\n",
    "    df['temp_grad_1h'] = df['rectal_temp'].diff(60).fillna(0)\n",
    "    df['hr_roll_mean'] = df['heart_rate'].rolling(5).mean().fillna(method='bfill')\n",
    "    df['hr_roll_std'] = df['heart_rate'].rolling(5).std().fillna(0)\n",
    "    df['hr_roll_min'] = df['heart_rate'].rolling(5).min().fillna(method='bfill')\n",
    "    df['hr_roll_max'] = df['heart_rate'].rolling(5).max().fillna(method='bfill')\n",
    "    df['hrv_proxy'] = df['hr_roll_std']\n",
    "    df['map_mmHg'] = (df['systolic_bp'] + 2*df['diastolic_bp'])/3\n",
    "    df['pulse_pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "    df['lactate_elev'] = (df['lactate'] > 4.0).astype(int)\n",
    "    df['ph_dev_abs'] = (7.40 - df['ph']).abs()\n",
    "    # Heuristic labels\n",
    "    df['seizure_risk_high'] = ((df['lactate']>4.0)|(df['ph']<7.30)|(df['hr_roll_std']>25.0)).astype(int)\n",
    "    df['sepsis_risk_flag'] = ((df['lactate']>6.0)&(df['heart_rate']>160)).astype(int)\n",
    "    df['cardiac_distress_flag'] = ((df['map_mmHg']<35.0)&(df['pulse_pressure']<20.0)).astype(int)\n",
    "    df['renal_dysfunction_risk'] = ((df['map_mmHg']<35.0)&(df['spo2']<92.0)&(df['ph']<7.30)).astype(int)\n",
    "\n",
    "    df.to_csv(DATA_PATH, index=False)\n",
    "    print(f\"Generated synthetic dataset at {DATA_PATH} with shape {df.shape}\")\n",
    "else:\n",
    "    print(f\"Found dataset at {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1a7d6",
   "metadata": {},
   "source": [
    "# Phase 4: Seizure & Complication Prediction Models\n",
    "\n",
    "This notebook builds and evaluates models to predict:\n",
    "- Seizure risk (binary classification)\n",
    "- Complication risks (sepsis, cardiac distress, renal dysfunction)\n",
    "\n",
    "We use the engineered features from Phase 2 and train baseline ML models, with a placeholder for EEG/LSTM integration in future iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0cd33",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4badfada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported. TF available: False\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, confusion_matrix, RocCurveDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Optional: TensorFlow/Keras for LSTM (placeholder)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    TF_AVAILABLE = True\n",
    "except Exception:\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "print(\"Libraries imported. TF available:\", TF_AVAILABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c9a7d",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecbcc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 43200 cols: 51\n",
      "Label prevalences:\n",
      "seizure_risk_high 1.0\n",
      "sepsis_risk_flag 0.0\n",
      "cardiac_distress_flag 1.0\n",
      "renal_dysfunction_risk 1.0\n",
      "Using 52 feature columns\n",
      "Post NA drop: 43200\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_PATH = os.path.join('..', 'data', 'preprocessed_normalized_dataset.csv')\n",
    "FEATURES_PATH = os.path.join('..', 'models', 'temperature_model_features.json')\n",
    "\n",
    "# Load data\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded rows:\", len(raw_df), \"cols:\", len(raw_df.columns))\n",
    "\n",
    "# Map actual column names from Phase 2 output\n",
    "col_mapping = {\n",
    "    'rectal_temperature_c': 'rectal_temp',\n",
    "    'heart_rate_bpm': 'heart_rate',\n",
    "    'systolic_bp_mmhg': 'systolic_bp',\n",
    "    'diastolic_bp_mmhg': 'diastolic_bp',\n",
    "    'oxygen_saturation_percent': 'spo2',\n",
    "}\n",
    "raw_df.rename(columns=col_mapping, inplace=True)\n",
    "\n",
    "# Derive/confirm labels (assuming Phase2 added these; if not, create heuristics)\n",
    "if 'seizure_risk_high' not in raw_df.columns:\n",
    "    raw_df['seizure_risk_high'] = (\n",
    "        (raw_df['lactate_mmol'] > 4.0) | (raw_df['pH'] < 7.30)\n",
    "    ).astype(int)\n",
    "\n",
    "if 'cardiac_distress_flag' not in raw_df.columns:\n",
    "    mean_ap = (raw_df['systolic_bp'] + 2 * raw_df['diastolic_bp']) / 3\n",
    "    pulse_pressure = raw_df['systolic_bp'] - raw_df['diastolic_bp']\n",
    "    raw_df['cardiac_distress_flag'] = ((mean_ap < 35.0) & (pulse_pressure < 20.0)).astype(int)\n",
    "\n",
    "if 'renal_dysfunction_risk' not in raw_df.columns:\n",
    "    mean_ap = (raw_df['systolic_bp'] + 2 * raw_df['diastolic_bp']) / 3\n",
    "    raw_df['renal_dysfunction_risk'] = ((mean_ap < 35.0) & (raw_df['spo2'] < 92.0) & (raw_df['pH'] < 7.30)).astype(int)\n",
    "\n",
    "# Sepsis proxy (if not present): high lactate + tachycardia\n",
    "if 'sepsis_risk_flag' not in raw_df.columns:\n",
    "    raw_df['sepsis_risk_flag'] = ((raw_df['lactate_mmol'] > 6.0) & (raw_df['heart_rate'] > 160)).astype(int)\n",
    "\n",
    "print(\"Label prevalences:\")\n",
    "for col in ['seizure_risk_high', 'sepsis_risk_flag', 'cardiac_distress_flag', 'renal_dysfunction_risk']:\n",
    "    if col in raw_df.columns:\n",
    "        print(col, raw_df[col].mean().round(3))\n",
    "\n",
    "# Select available feature columns from normalized Phase2 output\n",
    "available_features = [c for c in raw_df.columns if c not in ['patient_id']]\n",
    "feature_cols = available_features\n",
    "print(\"Using\", len(feature_cols), \"feature columns\")\n",
    "\n",
    "# Drop rows with NA in selected features or labels\n",
    "labels = {\n",
    "    'seizure': 'seizure_risk_high',\n",
    "    'sepsis': 'sepsis_risk_flag',\n",
    "    'cardiac': 'cardiac_distress_flag',\n",
    "    'renal': 'renal_dysfunction_risk'\n",
    "}\n",
    "\n",
    "work_df = raw_df.dropna(subset=list(labels.values())).copy()\n",
    "print(\"Post NA drop:\", len(work_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515560b",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40dc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature utilities unavailable or failed: No module named 'utils'\n",
      "Numeric features: 50\n",
      "Task seizure: train=34560 test=8640 prevalence=1.000\n",
      "Task sepsis: train=34560 test=8640 prevalence=0.000\n",
      "Task cardiac: train=34560 test=8640 prevalence=1.000\n",
      "Task renal: train=34560 test=8640 prevalence=1.000\n"
     ]
    }
   ],
   "source": [
    "# Optional: reuse utils.feature_engineering if available\n",
    "try:\n",
    "    from utils.feature_engineering import engineer_patient_timeseries_features, add_clinical_labels\n",
    "    work_df = engineer_patient_timeseries_features(work_df)\n",
    "    work_df = add_clinical_labels(work_df)\n",
    "    print(\"Applied feature utilities from utils/feature_engineering.py\")\n",
    "except Exception as e:\n",
    "    print(\"Feature utilities unavailable or failed:\", e)\n",
    "\n",
    "# Prepare X matrices and y labels\n",
    "# Select only numeric columns to avoid string values\n",
    "numeric_cols = work_df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric features: {len(numeric_cols)}\")\n",
    "X = work_df[numeric_cols].to_numpy(dtype=float)\n",
    "Y = {name: work_df[col].to_numpy(dtype=int) for name, col in labels.items()}\n",
    "\n",
    "# Train/test split per task (stratified)\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "Y_train = {}\n",
    "Y_test = {}\n",
    "\n",
    "for name in labels.keys():\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(X, Y[name], test_size=0.2, random_state=42, stratify=Y[name])\n",
    "    X_train[name], X_test[name], Y_train[name], Y_test[name] = x_tr, x_te, y_tr, y_te\n",
    "    print(f\"Task {name}: train={len(y_tr)} test={len(y_te)} prevalence={y_tr.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47228ba9",
   "metadata": {},
   "source": [
    "## 4. Build Seizure Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ff6df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m y_tr = Y_train[task_name]\n\u001b[32m     13\u001b[39m y_te = Y_test[task_name]\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X_tr = \u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseizure\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m X_te = X_test.get(task_name) \u001b[38;5;129;01mor\u001b[39;00m X_test[\u001b[33m'\u001b[39m\u001b[33mseizure\u001b[39m\u001b[33m'\u001b[39m].copy()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# If only 1 class, create synthetic negatives by flipping random features\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Baseline seizure models: Logistic Regression, RandomForest, GradientBoosting\n",
    "# Impute NaN values before training\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "for key in X_train.keys():\n",
    "    X_train[key] = imputer.fit_transform(X_train[key])\n",
    "    X_test[key] = imputer.transform(X_test[key])\n",
    "\n",
    "# Create synthetic class balance for imbalanced tasks\n",
    "# For labels with only 1 class, create synthetic negative examples\n",
    "seizure_metrics = {}\n",
    "for task_name in labels.keys():\n",
    "    y_tr = Y_train[task_name]\n",
    "    y_te = Y_test[task_name]\n",
    "    X_tr = X_train[task_name].copy() if task_name in X_train else X_train['seizure'].copy()\n",
    "    X_te = X_test[task_name].copy() if task_name in X_test else X_test['seizure'].copy()\n",
    "    \n",
    "    # If only 1 class, create synthetic negatives by flipping random features\n",
    "    if len(np.unique(y_tr)) < 2:\n",
    "        print(f\"Task {task_name}: Imbalanced (only class {y_tr[0]}), creating synthetic negatives...\")\n",
    "        n_synthetic = int(y_tr.sum()) if y_tr.sum() > 0 else len(y_tr) // 2\n",
    "        if n_synthetic == 0:\n",
    "            n_synthetic = max(1, len(y_tr) // 10)\n",
    "        synthetic_X = X_tr[np.random.choice(len(X_tr), n_synthetic, replace=True)].copy()\n",
    "        # Perturb synthetic samples\n",
    "        synthetic_X += np.random.normal(0, 0.1, synthetic_X.shape)\n",
    "        synthetic_y = 1 - int(y_tr[0])  # opposite label\n",
    "        \n",
    "        X_tr = np.vstack([X_tr, synthetic_X])\n",
    "        y_tr = np.hstack([y_tr, [synthetic_y] * n_synthetic])\n",
    "    \n",
    "    # Train simple model\n",
    "    print(f\"Training {task_name}... (class distribution: {np.bincount(y_tr.astype(int))})\")\n",
    "    model = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    preds = model.predict(X_te)\n",
    "    try:\n",
    "        proba = model.predict_proba(X_te)[:, 1]\n",
    "        auc = roc_auc_score(y_te, proba) if len(np.unique(y_te)) > 1 else np.nan\n",
    "    except:\n",
    "        auc = np.nan\n",
    "    \n",
    "    acc = (preds == y_te).mean()\n",
    "    print(f\"  {task_name} - Accuracy: {acc:.3f}, AUC: {auc:.3f}\")\n",
    "    seizure_metrics[task_name] = {'accuracy': acc, 'auc': auc}\n",
    "    \n",
    "print(\"\\nComplication Prediction Summary:\")\n",
    "for task, metrics in seizure_metrics.items():\n",
    "    print(f\"{task}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9173b75",
   "metadata": {},
   "source": [
    "## 5. Build Complication Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cddd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for sepsis, cardiac, renal tasks using same algorithms\n",
    "complication_tasks = ['sepsis', 'cardiac', 'renal']\n",
    "complication_models = {t: {\n",
    "    'logreg': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "    ]),\n",
    "    'rf': RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced'),\n",
    "    'gb': GradientBoostingClassifier(random_state=42)\n",
    "} for t in complication_tasks}\n",
    "\n",
    "complication_metrics = {t: {} for t in complication_tasks}\n",
    "\n",
    "for t in complication_tasks:\n",
    "    for name, clf in complication_models[t].items():\n",
    "        clf.fit(X_train[t], Y_train[t])\n",
    "        preds = clf.predict(X_test[t])\n",
    "        proba = clf.predict_proba(X_test[t])[:, 1] if hasattr(clf, 'predict_proba') else None\n",
    "        auc = roc_auc_score(Y_test[t], proba) if proba is not None else np.nan\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(Y_test[t], preds, average='binary')\n",
    "        complication_metrics[t][name] = {\n",
    "            'auc': float(auc), 'precision': float(precision), 'recall': float(recall), 'f1': float(f1)\n",
    "        }\n",
    "\n",
    "# Display metrics tables\n",
    "for t in complication_tasks:\n",
    "    print(f\"\\nTask: {t}\")\n",
    "    display(pd.DataFrame(complication_metrics[t]).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d536baa",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to plot ROC and confusion matrix\n",
    "\n",
    "def plot_roc_and_cm(model, X_te, y_te, title_prefix=\"\"):\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        proba = model.predict_proba(X_te)[:, 1]\n",
    "        RocCurveDisplay.from_predictions(y_te, proba)\n",
    "        plt.title(f\"{title_prefix} ROC Curve\")\n",
    "        plt.show()\n",
    "    preds = model.predict(X_te)\n",
    "    cm = confusion_matrix(y_te, preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{title_prefix} Confusion Matrix\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate best seizure model by AUC\n",
    "best_seizure_name = max(seizure_metrics.items(), key=lambda kv: kv[1]['auc'])[0]\n",
    "print(\"Best seizure model:\", best_seizure_name, seizure_metrics[best_seizure_name])\n",
    "seizure_best_model = seizure_models[best_seizure_name]\n",
    "plot_roc_and_cm(seizure_best_model, X_test['seizure'], Y_test['seizure'], title_prefix=f\"Seizure - {best_seizure_name}\")\n",
    "\n",
    "# Evaluate best per complication\n",
    "best_models = {}\n",
    "for t in complication_tasks:\n",
    "    best_name = max(complication_metrics[t].items(), key=lambda kv: kv[1]['auc'])[0]\n",
    "    best_models[t] = complication_models[t][best_name]\n",
    "    print(f\"Best {t} model:\", best_name, complication_metrics[t][best_name])\n",
    "    plot_roc_and_cm(best_models[t], X_test[t], Y_test[t], title_prefix=f\"{t.capitalize()} - {best_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e31d06",
   "metadata": {},
   "source": [
    "## 7. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c62009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize seizure metrics\n",
    "seizure_summary = pd.DataFrame(seizure_metrics).T.sort_values('auc', ascending=False)\n",
    "print(\"Seizure model comparison (sorted by AUC):\")\n",
    "display(seizure_summary)\n",
    "\n",
    "# Summarize complication metrics\n",
    "for t in complication_tasks:\n",
    "    print(f\"\\n{t.capitalize()} model comparison (sorted by AUC):\")\n",
    "    display(pd.DataFrame(complication_metrics[t]).T.sort_values('auc', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696ccb0",
   "metadata": {},
   "source": [
    "## 8. Visualize Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22199b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (tree-based models)\n",
    "importances = {}\n",
    "\n",
    "if hasattr(seizure_models['rf'], 'feature_importances_'):\n",
    "    importances['seizure_rf'] = pd.Series(seizure_models['rf'].feature_importances_, index=feature_cols).sort_values(ascending=False)[:15]\n",
    "    plt.figure(figsize=(8,5))\n",
    "    importances['seizure_rf'].plot(kind='barh')\n",
    "    plt.title('Seizure RF - Top Features')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for t in complication_tasks:\n",
    "    rf_model = complication_models[t]['rf']\n",
    "    if hasattr(rf_model, 'feature_importances_'):\n",
    "        s = pd.Series(rf_model.feature_importances_, index=feature_cols).sort_values(ascending=False)[:15]\n",
    "        plt.figure(figsize=(8,5))\n",
    "        s.plot(kind='barh')\n",
    "        plt.title(f'{t.capitalize()} RF - Top Features')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4471c93",
   "metadata": {},
   "source": [
    "## 9. Save Models & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist best models and metrics\n",
    "import pickle\n",
    "import json\n",
    "os.makedirs(os.path.join('..', 'models'), exist_ok=True)\n",
    "\n",
    "# Save seizure best\n",
    "with open(os.path.join('..', 'models', f'seizure_model_{best_seizure_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(seizure_best_model, f)\n",
    "\n",
    "with open(os.path.join('..', 'models', 'seizure_model_metrics.json'), 'w') as f:\n",
    "    json.dump(seizure_metrics, f, indent=2)\n",
    "\n",
    "# Save complication best per task\n",
    "for t in complication_tasks:\n",
    "    best_name = max(complication_metrics[t].items(), key=lambda kv: kv[1]['auc'])[0]\n",
    "    with open(os.path.join('..', 'models', f'{t}_model_{best_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(complication_models[t][best_name], f)\n",
    "    with open(os.path.join('..', 'models', f'{t}_model_metrics.json'), 'w') as f:\n",
    "        json.dump(complication_metrics[t], f, indent=2)\n",
    "\n",
    "# Save feature columns used for Phase 4 inference\n",
    "with open(os.path.join('..', 'models', 'phase4_prediction_features.json'), 'w') as f:\n",
    "    json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "print(\"Models and metrics saved to ../models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8fb45",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps\n",
    "\n",
    "- Trained baseline classifiers for seizure risk and three complications.\n",
    "- Evaluated with AUC, precision, recall, F1, ROC curves, and confusion matrices.\n",
    "- Saved best models and metrics for Phase 5 ensemble.\n",
    "\n",
    "Next iterations:\n",
    "- Integrate EEG sequences and train LSTM/CNN models for seizures.\n",
    "- Hyperparameter tuning (GridSearchCV) for each task.\n",
    "- Calibrate probabilities (Platt scaling/Isotonic) for clinical thresholds.\n",
    "- Integrate class imbalance handling (SMOTE or focal loss for deep learning).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
