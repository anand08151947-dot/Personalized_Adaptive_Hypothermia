{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20815d4",
   "metadata": {},
   "source": [
    "# Phase 3: Optimal Temperature Tuning Model\n",
    "## Personalized AI-Based Temperature Optimization for Therapeutic Hypothermia\n",
    "\n",
    "**Objective:** Build a machine learning regression model that predicts the individually optimal neuroprotective temperature based on the infant's real-time physiological data.\n",
    "\n",
    "**Key Components:**\n",
    "- Temperature Gradient Prediction (next 1-hour temperature)\n",
    "- Temperature Stability Assessment (minimize overshoot/undershoot)\n",
    "- Individualized Temperature Recommendations\n",
    "- Model Comparison (Random Forest, Gradient Boosting, Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419b2c5",
   "metadata": {},
   "source": [
    "## Section 1: Import Libraries and Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa37d2bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneural_network\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MLPRegressor\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed dataset...\")\n",
    "df = pd.read_csv('../data/preprocessed_normalized_dataset.csv')\n",
    "\n",
    "print(f\"✓ Dataset loaded: {df.shape}\")\n",
    "print(f\"Patients: {df['patient_id'].nunique()}\")\n",
    "print(f\"Time range: {df['time_hours'].min():.1f} to {df['time_hours'].max():.1f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36670ba",
   "metadata": {},
   "source": [
    "## Section 2: Prepare Data for Temperature Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a68fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing temperature prediction task...\\n\")\n",
    "\n",
    "# Create target variable: temperature 1 hour in the future\n",
    "df_model = df.copy().sort_values(['patient_id', 'time_hours']).reset_index(drop=True)\n",
    "\n",
    "# Create future temperature (target for regression)\n",
    "df_model['target_temp_next_1h'] = 0.0\n",
    "\n",
    "for patient_id in df_model['patient_id'].unique():\n",
    "    mask = df_model['patient_id'] == patient_id\n",
    "    indices = df_model[mask].index\n",
    "    \n",
    "    # Shift temperature forward by 12 measurements (1 hour with 5-min intervals)\n",
    "    future_temps = df_model.loc[indices, 'rectal_temperature_c'].shift(-12).values\n",
    "    df_model.loc[indices, 'target_temp_next_1h'] = future_temps\n",
    "\n",
    "# Remove last 12 rows of each patient (no future data)\n",
    "df_model = df_model.dropna(subset=['target_temp_next_1h'])\n",
    "\n",
    "# Select features for the model\n",
    "feature_cols = [col for col in df_model.columns if col not in [\n",
    "    'patient_id', 'time_minutes', 'time_hours', 'rectal_temperature_c', \n",
    "    'target_temp_c', 'hie_severity', 'target_temp_next_1h', 'baseline_patient_id',\n",
    "    'baseline_birth_hour', 'baseline_core_temp'\n",
    "] and not col.startswith('baseline_')]\n",
    "\n",
    "# Add some baseline features for personalization\n",
    "baseline_features = ['baseline_birth_weight_kg', 'baseline_gestational_age_weeks', \n",
    "                     'baseline_seizure_risk_factor']\n",
    "feature_cols = feature_cols + baseline_features\n",
    "\n",
    "print(f\"Total features for temperature model: {len(feature_cols)}\")\n",
    "print(f\"Training samples: {len(df_model):,}\")\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "df_model_clean = df_model[feature_cols + ['target_temp_next_1h', 'hie_severity']].dropna()\n",
    "\n",
    "print(f\"Clean samples after removing NaN: {len(df_model_clean):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and testing data\n",
    "X = df_model_clean[feature_cols].values\n",
    "y = df_model_clean['target_temp_next_1h'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training set: {len(X_train):,} samples\")\n",
    "print(f\"  Testing set: {len(X_test):,} samples\")\n",
    "print(f\"  Feature dimensions: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"  Mean: {y.mean():.2f}°C\")\n",
    "print(f\"  Std: {y.std():.2f}°C\")\n",
    "print(f\"  Min: {y.min():.2f}°C\")\n",
    "print(f\"  Max: {y.max():.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451958e",
   "metadata": {},
   "source": [
    "## Section 3: Train Multiple Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training temperature prediction models...\\n\")\n",
    "\n",
    "# Dictionary to store models and results\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Model 1: Random Forest Regressor\n",
    "print(\"1. Training Random Forest Regressor...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=15, \n",
    "                                 random_state=42, n_jobs=-1, verbose=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test, rf_pred)\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "results['Random Forest'] = {\n",
    "    'MSE': rf_mse, 'RMSE': rf_rmse, 'R2': rf_r2, 'MAE': rf_mae,\n",
    "    'predictions': rf_pred\n",
    "}\n",
    "print(f\"   ✓ RMSE: {rf_rmse:.4f}°C, R²: {rf_r2:.4f}, MAE: {rf_mae:.4f}°C\")\n",
    "\n",
    "# Model 2: Gradient Boosting Regressor\n",
    "print(\"\\n2. Training Gradient Boosting Regressor...\")\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, \n",
    "                                     max_depth=5, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_test)\n",
    "gb_mse = mean_squared_error(y_test, gb_pred)\n",
    "gb_rmse = np.sqrt(gb_mse)\n",
    "gb_r2 = r2_score(y_test, gb_pred)\n",
    "gb_mae = mean_absolute_error(y_test, gb_pred)\n",
    "\n",
    "models['Gradient Boosting'] = gb_model\n",
    "results['Gradient Boosting'] = {\n",
    "    'MSE': gb_mse, 'RMSE': gb_rmse, 'R2': gb_r2, 'MAE': gb_mae,\n",
    "    'predictions': gb_pred\n",
    "}\n",
    "print(f\"   ✓ RMSE: {gb_rmse:.4f}°C, R²: {gb_r2:.4f}, MAE: {gb_mae:.4f}°C\")\n",
    "\n",
    "# Model 3: Neural Network (MLP)\n",
    "print(\"\\n3. Training Neural Network (MLP)...\")\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(128, 64, 32), learning_rate_init=0.001,\n",
    "                       max_iter=500, random_state=42, early_stopping=True, \n",
    "                       validation_fraction=0.1, verbose=0)\n",
    "nn_model.fit(X_train, y_train)\n",
    "nn_pred = nn_model.predict(X_test)\n",
    "nn_mse = mean_squared_error(y_test, nn_pred)\n",
    "nn_rmse = np.sqrt(nn_mse)\n",
    "nn_r2 = r2_score(y_test, nn_pred)\n",
    "nn_mae = mean_absolute_error(y_test, nn_pred)\n",
    "\n",
    "models['Neural Network'] = nn_model\n",
    "results['Neural Network'] = {\n",
    "    'MSE': nn_mse, 'RMSE': nn_rmse, 'R2': nn_r2, 'MAE': nn_mae,\n",
    "    'predictions': nn_pred\n",
    "}\n",
    "print(f\"   ✓ RMSE: {nn_rmse:.4f}°C, R²: {nn_r2:.4f}, MAE: {nn_mae:.4f}°C\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON - TEMPERATURE PREDICTION (1-Hour Ahead)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': results.keys(),\n",
    "    'RMSE (°C)': [results[m]['RMSE'] for m in results.keys()],\n",
    "    'MAE (°C)': [results[m]['MAE'] for m in results.keys()],\n",
    "    'R² Score': [results[m]['R2'] for m in results.keys()]\n",
    "})\n",
    "comparison_df = comparison_df.sort_values('RMSE (°C)')\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"\\n✓ Best performing model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bd97a",
   "metadata": {},
   "source": [
    "## Section 4: Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b014f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Temperature Prediction Models - Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "colors = ['#2ecc71', '#e74c3c', '#3498db']\n",
    "\n",
    "# Plot 1: Actual vs Predicted comparison\n",
    "ax = axes[0, 0]\n",
    "for idx, (model_name, pred) in enumerate([(m, results[m]['predictions']) for m in results.keys()]):\n",
    "    ax.scatter(y_test, pred, alpha=0.5, label=model_name, s=20, color=colors[idx])\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Temperature (°C)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Predicted Temperature (°C)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Actual vs Predicted Temperatures', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: RMSE comparison\n",
    "ax = axes[0, 1]\n",
    "rmse_values = [results[m]['RMSE'] for m in results.keys()]\n",
    "bars = ax.bar(results.keys(), rmse_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('RMSE (°C)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Root Mean Squared Error Comparison', fontsize=12, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for i, (bar, val) in enumerate(zip(bars, rmse_values)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 3: R² Score comparison\n",
    "ax = axes[1, 0]\n",
    "r2_values = [results[m]['R2'] for m in results.keys()]\n",
    "bars = ax.bar(results.keys(), r2_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax.set_ylabel('R² Score', fontsize=11, fontweight='bold')\n",
    "ax.set_title('R² Score Comparison', fontsize=12, fontweight='bold')\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "for i, (bar, val) in enumerate(zip(bars, r2_values)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 4: Prediction error distribution\n",
    "ax = axes[1, 1]\n",
    "for idx, (model_name, pred) in enumerate([(m, results[m]['predictions']) for m in results.keys()]):\n",
    "    errors = y_test - pred\n",
    "    ax.hist(errors, bins=30, alpha=0.5, label=model_name, color=colors[idx], edgecolor='black')\n",
    "ax.set_xlabel('Prediction Error (°C)', fontsize=11, fontweight='bold')\n",
    "ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Distribution of Prediction Errors', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axvline(x=0, color='k', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/temperature_model_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Performance visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe8a7b",
   "metadata": {},
   "source": [
    "## Section 5: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from tree-based models\n",
    "print(\"Analyzing feature importance...\\n\")\n",
    "\n",
    "# Random Forest feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Gradient Boosting feature importance\n",
    "gb_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualize top features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('Feature Importance - Temperature Prediction Models', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Random Forest\n",
    "ax = axes[0]\n",
    "top_rf = rf_importance.head(12)\n",
    "bars = ax.barh(range(len(top_rf)), top_rf['importance'].values, color='#2ecc71', edgecolor='black')\n",
    "ax.set_yticks(range(len(top_rf)))\n",
    "ax.set_yticklabels(top_rf['feature'].values)\n",
    "ax.set_xlabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Random Forest - Top 12 Features', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Gradient Boosting\n",
    "ax = axes[1]\n",
    "top_gb = gb_importance.head(12)\n",
    "bars = ax.barh(range(len(top_gb)), top_gb['importance'].values, color='#e74c3c', edgecolor='black')\n",
    "ax.set_yticks(range(len(top_gb)))\n",
    "ax.set_yticklabels(top_gb['feature'].values)\n",
    "ax.set_xlabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Gradient Boosting - Top 12 Features', fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/temperature_model_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features (Random Forest):\")\n",
    "print(rf_importance.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n✓ Feature importance analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c274f",
   "metadata": {},
   "source": [
    "## Section 6: Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63455aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "# Save models\n",
    "print(\"Saving models and results...\\n\")\n",
    "\n",
    "# Save best performing model\n",
    "best_model = models[best_model_name]\n",
    "with open('../models/temperature_optimization_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f\"✓ Best model ({best_model_name}) saved\")\n",
    "\n",
    "# Save all models\n",
    "for model_name, model in models.items():\n",
    "    safe_name = model_name.lower().replace(' ', '_')\n",
    "    with open(f'../models/temperature_model_{safe_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "# Save results summary\n",
    "results_summary = {\n",
    "    'best_model': best_model_name,\n",
    "    'comparison': {\n",
    "        model: {\n",
    "            'RMSE': float(results[model]['RMSE']),\n",
    "            'MAE': float(results[model]['MAE']),\n",
    "            'R2': float(results[model]['R2'])\n",
    "        } for model in results.keys()\n",
    "    },\n",
    "    'test_set_size': len(y_test),\n",
    "    'train_set_size': len(y_train),\n",
    "    'feature_count': len(feature_cols)\n",
    "}\n",
    "\n",
    "with open('../models/temperature_model_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "# Save feature names for inference\n",
    "with open('../models/temperature_model_features.json', 'w') as f:\n",
    "    json.dump(feature_cols, f, indent=2)\n",
    "\n",
    "print(\"✓ All models saved to ../models/\")\n",
    "print(f\"✓ Results summary saved\")\n",
    "print(f\"✓ Feature list saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 3 SUMMARY - TEMPERATURE OPTIMIZATION MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"  RMSE: {results[best_model_name]['RMSE']:.4f}°C\")\n",
    "print(f\"  MAE: {results[best_model_name]['MAE']:.4f}°C\")\n",
    "print(f\"  R² Score: {results[best_model_name]['R2']:.4f}\")\n",
    "print(f\"\\nModel predicts optimal temperature 1 hour ahead\")\n",
    "print(f\"Training samples: {len(X_train):,}\")\n",
    "print(f\"Features used: {len(feature_cols)}\")\n",
    "print(f\"\\nReady for Phase 4: Seizure and Complication Prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
